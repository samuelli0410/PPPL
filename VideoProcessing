import sys
from pathlib import Path
import csv
import numpy as np
from matplotlib import pyplot as plt
from matplotlib.animation import FuncAnimation 
import os
import imageio.v2 as imageio
from tqdm import tqdm
import torch
csv.field_size_limit(sys.maxsize)
project_root = Path(__file__).parent.parent
data_dir = project_root / "data"
sys.path.append(str(project_root))
sav_files_dir = data_dir / "TestData"
from data.file_utils import GetPkl
from working_dir.ResNet.EncoderTrain import Autoencoder, AutoencoderSRCNN,VAEAutoencoder
from working_dir.GAN.GAN import UNet
from working_dir.MLP.MLP import MLP


em = GetPkl(file_path=sav_files_dir)
files = em.list_files(display=True)

test,_ = em.load_processed(files[0])
# print(np.array(test).shape)
# print(test.shape[0])


def InvertVid(modelWeights, name, model=Autoencoder, FileNumber = 0):
    frames,_ = em.load_processed(files[FileNumber])
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model=model().to(device)
    model.load_state_dict(torch.load(modelWeights, map_location=device))
    model.eval()

    if name == "GAN":
        for j in tqdm(range(frames.shape[0]), desc="Generating Frames"):
            test_input =frames[j]
            test_input = test_input / test_input.max()
            test_tensor = torch.tensor(test_input, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
            # test_tensor = test_tensor.repeat(1, 3, 1, 1)
            with torch.no_grad():
                test_output = model(test_tensor)
            test_output = test_output.view(201, 201).cpu().numpy()
            test_output = (test_output - test_output.min()) / (test_output.max() - test_output.min())

            fig, axs = plt.subplots(1, 2, figsize=(15, 5))
            axs[0].imshow(test_input, cmap='inferno', aspect='auto')
            axs[0].set_title(f"Cam Image {j}")
            fig.colorbar(axs[0].images[0], ax=axs[0])
            for i, img, title in zip([1], [test_output], [f"{name} Generated Inversion"]):
                axs[i].imshow(img, cmap='inferno', aspect='equal')
                axs[i].set_title(title)
                fig.colorbar(axs[i].images[0], ax=axs[i])
            fig.tight_layout()
            plt.savefig(f"frames/frame_{j:03d}.png")
            plt.close(fig)

    elif name == "MLP":
        for j in tqdm(range(frames.shape[0]), desc="Generating Frames"):
            test_input = frames[j]
            test_input = test_input / test_input.max()
            test_tensor = torch.tensor(test_input, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
            test_tensor = test_tensor.repeat(1, 3, 1, 1)
            input_flat = test_tensor.view(1, -1)
            with torch.no_grad():
                test_output = model(input_flat)
            test_output = test_output.view(201, 201).cpu().numpy()
            test_output = (test_output - test_output.min()) / (test_output.max() - test_output.min())
            fig, axs = plt.subplots(1, 2, figsize=(15, 5))
            axs[0].imshow(test_input, cmap='inferno', aspect='auto')
            axs[0].set_title(f"Cam Image {j}")
            fig.colorbar(axs[0].images[0], ax=axs[0])
            for i, img, title in zip([1], [test_output], [f"{name} Generated Inversion"]):
                axs[i].imshow(img, cmap='inferno', aspect='equal')
                axs[i].set_title(title)
                fig.colorbar(axs[i].images[0], ax=axs[i])
            fig.tight_layout()
            plt.savefig(f"frames/frame_{j:03d}.png")
            plt.close(fig)       
    else:
        for j in tqdm(range(frames.shape[0]), desc="Generating Frames"):
            test_input =frames[j]
            test_input = test_input / test_input.max()
            test_tensor = torch.tensor(test_input, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
            test_tensor = test_tensor.repeat(1, 3, 1, 1)
            with torch.no_grad():
                test_output = model(test_tensor.to(device))
                test_output = test_output.squeeze().cpu().numpy()
            fig, axs = plt.subplots(1, 2, figsize=(15, 5))
            axs[0].imshow(test_input, cmap='inferno', aspect='auto')
            axs[0].set_title(f"Cam Image {j}")
            fig.colorbar(axs[0].images[0], ax=axs[0])
            for i, img, title in zip([1], [test_output], [f"{name} Generated Inversion"]):
                axs[i].imshow(img, cmap='inferno', aspect='equal')
                axs[i].set_title(title)
                fig.colorbar(axs[i].images[0], ax=axs[i])
            fig.tight_layout()
            plt.savefig(f"frames/frame_{j:03d}.png")
            plt.close(fig)
    
    with imageio.get_writer(f"/scratch/gpfs/sl4318/Outputs/TestData{name}.mp4", fps=10) as writer:
        for i in range(frames.shape[0]):
            filename = f"frames/frame_{i:03d}.png"
            image = imageio.imread(filename)
            writer.append_data(image)
    print(f"{name} Video saved")




    
if __name__ == "__main__":
    print("Start")
    # InvertVid("/scratch/gpfs/sl4318/Outputs/Weights/ResNetSRCNN.pth", "ResNetSRCNN", AutoencoderSRCNN)
    # InvertVid("/scratch/gpfs/sl4318/Outputs/Weights/resNet.pth", "ResNet", Autoencoder)
    # InvertVid("/scratch/gpfs/sl4318/Outputs/Weights/VAEresNet.pth", "VAE", VAEAutoencoder)

    # InvertVid("/scratch/gpfs/sl4318/Outputs/Weights/MLP.pth", "MLP", MLP)
    InvertVid("/scratch/gpfs/sl4318/Outputs/Weights/GAN.pth", "GAN", UNet)


